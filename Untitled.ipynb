{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1851d90-204a-4a7d-8345-26f2e7f5444d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bab42f0-5574-49e2-8576-71c48edf7ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"textdata.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43cee01a-42bd-472c-980d-c02e34a04f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      label                                       commentaires\n",
       "0      neg  I don't have much to say about this movie. It ...\n",
       "1      neg  Race car drivers say that 100 mph seems fast t...\n",
       "2      neg  I found this film to be quite an oddity. From ...\n",
       "3      neg  Jane Russell proved to be a delightful musical...\n",
       "4      neg  This movie makes Canadians and Brits out to be...\n",
       "...    ...                                                ...\n",
       "1995   pos  Personally, I disdain The Jerry Springer Show,...\n",
       "1996   pos  I saw this film at the Rhode Island Internatio...\n",
       "1997   pos  There's a lot going on in The College Girl Mur...\n",
       "1998   pos  Richard Linklater's beautifully directed mixtu...\n",
       "1999   pos  This is a very memorable spaghetti western. It...\n",
       "\n",
       "[2000 rows x 2 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c15fc7a4-8b98-4e6f-a2a8-ba35c1df3144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.count of      label                                       commentaires\n",
       "0      neg  I don't have much to say about this movie. It ...\n",
       "1      neg  Race car drivers say that 100 mph seems fast t...\n",
       "2      neg  I found this film to be quite an oddity. From ...\n",
       "3      neg  Jane Russell proved to be a delightful musical...\n",
       "4      neg  This movie makes Canadians and Brits out to be...\n",
       "...    ...                                                ...\n",
       "1995   pos  Personally, I disdain The Jerry Springer Show,...\n",
       "1996   pos  I saw this film at the Rhode Island Internatio...\n",
       "1997   pos  There's a lot going on in The College Girl Mur...\n",
       "1998   pos  Richard Linklater's beautifully directed mixtu...\n",
       "1999   pos  This is a very memorable spaghetti western. It...\n",
       "\n",
       "[2000 rows x 2 columns]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f78fbcf0-98b3-4272-9746-03be03bbc140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d1a5054-5234-4636-a2a0-b39a698c723b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'commentaires'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14a5fd3b-8325-431e-a8f4-4be4a76956b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1592"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "essai = df[\"commentaires\"][1]\n",
    "len(essai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed97e234-774c-4a3b-90a5-32030bf23aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df[\"commentaires\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3605fac-b8c7-4102-a863-1f4ddf50ad28",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad16452b-3496-4b50-93ca-97c847b3a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = test.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43f19dd0-0798-46b0-ad88-f5467035bb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c1457e4-b414-4750-9788-d442fcada7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddfc398d-c892-4895-a6ad-6d7eb7fdfc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ponctuations = list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a3619b5-a987-4ac8-b4d7-539eb7522eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_words(text,to_remove):\n",
    "    allowed_word_list = []\n",
    "    for i in text.replace(\",\",\"\").replace(\".\",\"\").replace(\";\",\"\").replace(\"?\",\"\").replace(\"!\",\"\").split():\n",
    "        if i not in to_remove:\n",
    "            allowed_word_list.append(i)\n",
    "    return \" \".join(allowed_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b45404d-1ab2-49a3-8e15-e7faa18dcf35",
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = remove_words(test,ponctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53d870d4-5628-44b1-94ed-b2e46629ac44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liste des stop words\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8ce17ed-4a51-4085-9f16-e12bf6ae0c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stopwords.words(\"english\")\n",
    "test = essai.lower()\n",
    "test1 = remove_words(test,ponctuations)\n",
    "test2 = remove_words(test,stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b57be5d-57cc-4254-a47e-aa5e93549f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1592\n",
      "1551\n",
      "1186\n"
     ]
    }
   ],
   "source": [
    "print(len(test))\n",
    "print(len(test1))\n",
    "print(len(test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4eb9db57-bccd-4fe9-b64f-b698fb6caa43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"race car drivers say 100 mph seems fast till driven 150 150 mph seems fast till driven 250<br /><br />ok<br /><br />andalusian dog seems breathtakingly bizarre till seen eraserhead eraserhead seems breathtakingly bizarre till seen begotten<br /><br />and begotten seems breathtakingly bizarre till seen works c frederic hobbs race fans nothing world film like works c frederic hobbs<br /><br />alabama's ghost comes close films coherent plot involves hippies rock concerts voodoo ghosts vampires robots magicians corrupt multinational corporations elephants mystery gas fabulous woodmobile cruising sunset district san francisco course<br /><br />what's really startling somebody gave lot money make alabama's ghost there's sets lighting hundreds extras costumes lots lots effects somehow makes alabama's ghost wrong watch awful cheeseball like night horror plutonium baby least part weirdness excusable basis obviously making film headroom discover cards alabama's ghost made actual budget that's evil mean got script tribe cannibals living thunder bay ontario building secret temple woods twizzlers nobody's beating door waving checkbook - guy get funds four flakiest movies ever made\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f68a18-521b-4f7b-a4f0-44cc7b919e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c00c6358-4ae3-4d90-b584-be79fbb35556",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec201db7-a000-4402-b273-fb6a448c688c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program => program\n",
      "programs => program\n",
      "programmer => programm\n",
      "programming => program\n",
      "programmers => programm\n",
      "habit => habit\n",
      "habitation => habit\n",
      "habiter => habit\n",
      "habits => habit\n",
      "habitations => habit\n"
     ]
    }
   ],
   "source": [
    "words = [\"program\",\"programs\",\"programmer\",\"programming\",\"programmers\",\"habit\", \"habitation\", \"habiter\",\"habits\", \"habitations\"]\n",
    "for w in words:\n",
    "    print(w, \"=>\", ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e42871-031e-49dd-bb31-cb8a5ffad676",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0158c18-1fd4-41f1-aca0-659aa53d8150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading wordnet: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading averaged_perceptron_tagger: <urlopen error\n",
      "[nltk_data]     [Errno 11001] getaddrinfo failed>\n",
      "[nltk_data] Error loading punkt_tab: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n",
      "[nltk_data] Error loading averaged_perceptron_tagger_eng: <urlopen\n",
      "[nltk_data]     error [Errno 11001] getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"averaged_perceptron_tagger\") # required for tagging\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ac16129-4aad-45f5-8f11-d251950ae524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemma : speak \n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "word = \"speaking\"\n",
    "lemma_noun = lemmatizer.lemmatize(word, pos = \"v\")\n",
    "print(f\"Lemma : {lemma_noun} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "655b761c-3d6d-46d6-93c3-539f66b70377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fonction\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49694c11-34ff-4e08-b388-173805a93ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_wordnet_pos(\"better\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "205be927-f8c6-4839-8c42-52e8cb3a1de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'striped', 'bars', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The striped bars are hanging on their feet for best\"\n",
    "tokenize_words = nltk.word_tokenize(sentence)\n",
    "print(tokenize_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931a816b-2c17-4b92-8d1e-821c6907b8bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "710dd567-f64c-473b-b98c-43e2b64eb6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first\n",
    "def lem(sentence):\n",
    "    tok = nltk.word_tokenize(sentence)\n",
    "    i = 0\n",
    "    for m in tok:\n",
    "        l = lemmatizer.lemmatize(m, pos = get_wordnet_pos(m))\n",
    "        tok[i] = l\n",
    "        i = i + 1\n",
    "    return \" \".join(tok)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f837dc40-1255-4b4f-9e20-186d15b9d2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The strip bar be hang on their foot for best'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f3f21e17-c0ec-4cf1-9dde-410b0391744f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second\n",
    "def lem_fct(sentence):\n",
    "    tokenize_words = nltk.word_tokenize(sentence)\n",
    "    for word in tokenize_words:\n",
    "        lem_word = lemmatizer.lemmatize(word, pos = get_wordnet_pos(word))\n",
    "        tokenize_words[tokenize_words.index(word)] = lem_word\n",
    "    return \" \".join(tokenize_words)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1947d175-1132-4f60-a792-5c9f65edea36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The striped bars are hanging on their feet for best\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The strip bar be hang on their foot for best'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem_fct(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2d3febe3-9523-4ce0-8ac4-747bb8f4fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Je su;is fo.rt en P?ython\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "308c46fd-86f3-4699-bf5b-f4aa727b9fdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "je su;is fo.rt en p?ython\n",
      "Je suis fort en Python\n"
     ]
    }
   ],
   "source": [
    "# Enlever les caracters\n",
    "def remove_punctuation(text):\n",
    "    allowed_words_list = []\n",
    "    for words in text.split():\n",
    "        allowed_words = []\n",
    "        for c in list(words):      \n",
    "            if c not in string.punctuation:\n",
    "                allowed_words.append(c)\n",
    "        allowed_words_list.append(\"\".join(allowed_words))\n",
    "    return \" \".join(allowed_words_list)\n",
    "    \n",
    "test = prompt.lower()\n",
    "test2 = remove_punctuation(prompt)\n",
    "print(test)\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "713ebfec-1ae9-44e6-8fc1-09dad83042c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test00 = \"Pouvez vous mettre le lien du logiciel s'il vous plait\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "93c917e9-2224-4b01-aa5c-2d3e9cac2293",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_sent(text,number):\n",
    "    allowed_words_list = []\n",
    "    for words in text.split():\n",
    "        if len(words) > number:\n",
    "            allowed_words_list.append(words)\n",
    "    return \" \".join(allowed_words_list)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26133fe3-216b-44aa-bcb5-dc998d912e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pouvez mettre logiciel plait'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_sent(test00,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5224c5e6-8fa0-4e81-8b10-8062fd9fe31a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "going fun\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['go', 'fun']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nettoyage(\"going is fun!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "813bb8c9-051a-4031-a6e4-8a9db8021b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial corpus      label                                       commentaires\n",
      "0      neg  I don't have much to say about this movie. It ...\n",
      "1      neg  Race car drivers say that 100 mph seems fast t...\n",
      "2      neg  I found this film to be quite an oddity. From ...\n",
      "3      neg  Jane Russell proved to be a delightful musical...\n",
      "4      neg  This movie makes Canadians and Brits out to be...\n",
      "...    ...                                                ...\n",
      "1995   pos  Personally, I disdain The Jerry Springer Show,...\n",
      "1996   pos  I saw this film at the Rhode Island Internatio...\n",
      "1997   pos  There's a lot going on in The College Girl Mur...\n",
      "1998   pos  Richard Linklater's beautifully directed mixtu...\n",
      "1999   pos  This is a very memorable spaghetti western. It...\n",
      "\n",
      "[2000 rows x 2 columns]\n",
      "*\n",
      "Clean corpus tokenized [['label'], ['commentaires']]\n",
      "*\n",
      "vocabulary ==>  ['commentaires', 'label']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import string\n",
    "\n",
    "def nettoyage(text):\n",
    "    # mettre le text en miniscule\n",
    "    text = text.lower()\n",
    "    # Enlever les caracteres\n",
    "    text = remove_punctuation(text)\n",
    "        ##text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "   # Enlever les stops words\n",
    "    text =  remove_words(text,stopwords.words(\"english\"))\n",
    "    # Faire la lemmatisation\n",
    "    text = lem_fct(text)\n",
    "    # tokenize document\n",
    "    tokens =  text.split()\n",
    "    return tokens\n",
    "    \n",
    "corpus = [\n",
    "    \"Python is amazing and fun\",\n",
    "    \"Python is not just fun but also powerful\",\n",
    "    \"Learning Python is fun\"\n",
    "]\n",
    "\n",
    "clean_corpus = [nettoyage(sentence) for sentence in corpus]\n",
    "print(\"Initial corpus\",corpus)\n",
    "print(\"*\")\n",
    "print(\"Clean corpus tokenized\", clean_corpus)\n",
    "print(\"*\")\n",
    "vocabulary = set()\n",
    "for sentence in clean_corpus:\n",
    "        vocabulary.update(sentence)\n",
    "vocabulary = sorted(list(vocabulary))\n",
    "print(\"vocabulary ==> \", vocabulary) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b754065a-a669-413e-a0ee-8894a45b375b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag of Words Vectors:\n",
      "[0, 1, 1, 0, 0, 1]\n",
      "[1, 0, 1, 0, 1, 1]\n",
      "[0, 0, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "# Calculate word frequencies vector\n",
    "def create_bow_vector(sentence,vocab):\n",
    "    vector = [0] * len(vocab)  # Initialize a vector of zeros\n",
    "    for word in sentence:\n",
    "        if word in vocab:\n",
    "            idx = vocab.index(word) # Find the index of the word in the vocabulary\n",
    "            vector[idx] += 1 # Increment\n",
    "    return vector\n",
    "\n",
    "# Create Bow vector for each sentence in the processed cropus\n",
    "bow_vectors = [create_bow_vector(sentence, vocabulary) for sentence in clean_corpus]\n",
    "print(\"Bag of Words Vectors:\")\n",
    "for vector in bow_vectors:\n",
    "    print(vector)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "90eb0cff-4d6b-4ddd-966d-c48f90729c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Race car drivers say that 100 mph seems fast till you've driven 150, and 150 mph seems fast till you've driven 250.<br /><br />OK.<br /><br />Andalusian Dog seems breathtakingly bizarre till you've seen Eraserhead, and Eraserhead seems breathtakingly bizarre till you've seen Begotten.<br /><br />And Begotten seems breathtakingly bizarre till you've seen the works of C. Frederic Hobbs. Race fans, there is NOTHING in all the world of film like the works of C. Frederic Hobbs.<br /><br />Alabama's Ghost comes as close as any of his films to having a coherent plot, and it only involves hippies, rock concerts, voodoo, ghosts, vampires, robots, magicians, corrupt multinational corporations, elephants and Mystery Gas. And the Fabulous Woodmobile, cruising the Sunset District in San Francisco, of course.<br /><br />What's really startling is that somebody gave him a LOT of money to make Alabama's Ghost. There's sets, lighting, hundreds of extras, costumes, lots and lots of effects. Somehow that makes Alabama's Ghost SO WRONG. You watch some awful cheeseball like Night of Horror or Plutonium Baby, and at least some part of the weirdness is excusable on the basis that they were obviously making the film off the headroom on their Discover cards. But Alabama's Ghost was made with an actual budget, and that's EVIL. I mean, I've got a script about a tribe of cannibals living in Thunder Bay, Ontario, building a secret temple in the woods out of Twizzlers, and nobody's beating down MY door waving a checkbook - how did this guy get the funds for FOUR of the flakiest movies ever made?\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "22c8e84d-1c29-41af-b8ad-c7da550532d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>commentaires</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>I don't have much to say about this movie. It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>Race car drivers say that 100 mph seems fast t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>I found this film to be quite an oddity. From ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>Jane Russell proved to be a delightful musical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>This movie makes Canadians and Brits out to be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>pos</td>\n",
       "      <td>Personally, I disdain The Jerry Springer Show,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>pos</td>\n",
       "      <td>I saw this film at the Rhode Island Internatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>pos</td>\n",
       "      <td>There's a lot going on in The College Girl Mur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>pos</td>\n",
       "      <td>Richard Linklater's beautifully directed mixtu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>pos</td>\n",
       "      <td>This is a very memorable spaghetti western. It...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                       commentaires\n",
       "0      neg  I don't have much to say about this movie. It ...\n",
       "1      neg  Race car drivers say that 100 mph seems fast t...\n",
       "2      neg  I found this film to be quite an oddity. From ...\n",
       "3      neg  Jane Russell proved to be a delightful musical...\n",
       "4      neg  This movie makes Canadians and Brits out to be...\n",
       "...    ...                                                ...\n",
       "1995   pos  Personally, I disdain The Jerry Springer Show,...\n",
       "1996   pos  I saw this film at the Rhode Island Internatio...\n",
       "1997   pos  There's a lot going on in The College Girl Mur...\n",
       "1998   pos  Richard Linklater's beautifully directed mixtu...\n",
       "1999   pos  This is a very memorable spaghetti western. It...\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f8391-a579-4979-9bf8-37f63bbb02e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
